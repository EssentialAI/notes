
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Epsilon Greedy explained &#8212; Notes @ The Essential AI</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://essentialai.github.io/essentialai.github.io/rl/epsilon-greedy.html" />
    <link rel="shortcut icon" href="../_static/brain1.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimistic initial values" href="optimistic-initial-values.html" />
    <link rel="prev" title="A/B/n testing using online advertising scenario" href="ab-testing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/lightmode.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Notes @ The Essential AI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to Notes @ Essential AI
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cvip/intro.html">
   Computer Vision and Image Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/pinhole.html">
     Introduction and the Pinhole camera
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/CVIP_Project1.html">
     CVIP-project-1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-transformations.html">
     Image Transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-formation.html">
     Image Formation and Stereo Vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-rectification.html">
     How to rectify two cameras?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-features.html">
     Image Features and Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/using-scale-as-feature.html">
     Using scale as a feature for correspondence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/feature-matching.html">
     Feature Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-filtering.html">
     Image Filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cvip/image-fourier-analysis.html">
     Image Fourier Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Reinforcement Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="mab.html">
     The Multi-Armed Bandit problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mab-code.html">
     Coding a simple (random) Multi-Armed Bandit Agent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ab-testing.html">
     A/B/n testing using online advertising scenario
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Epsilon Greedy explained
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimistic-initial-values.html">
     Optimistic initial values
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/EssentialAI/notes/main?urlpath=tree/rl/epsilon-greedy.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/rl/epsilon-greedy.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Epsilon Greedy explained
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-to-the-online-advertising-scenario">
   Application to the online advertising scenario
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advantages-and-disadvantages-of-epsilon-greedy-actions">
   Advantages and disadvantages of
   <span class="math notranslate nohighlight">
    \(\epsilon\)
   </span>
   -greedy actions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Epsilon Greedy explained</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Epsilon Greedy explained
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-to-the-online-advertising-scenario">
   Application to the online advertising scenario
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advantages-and-disadvantages-of-epsilon-greedy-actions">
   Advantages and disadvantages of
   <span class="math notranslate nohighlight">
    \(\epsilon\)
   </span>
   -greedy actions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="epsilon-greedy-explained">
<h1>Epsilon Greedy explained<a class="headerlink" href="#epsilon-greedy-explained" title="Permalink to this headline">#</a></h1>
<p>An easy-to-implement, effective, and widely used approach to the exploration-exploitation problem is what is called <span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy actions. This approach suggests, most of the time, greedily taking the action that is the best according to the rewards observed by that point in the experiment (that is, with 1-<span class="math notranslate nohighlight">\(\epsilon\)</span> probability); but once in a while (that is, with <span class="math notranslate nohighlight">\(\epsilon\)</span> probability), take a random action regardless of the action performances. Here, <span class="math notranslate nohighlight">\(\epsilon\)</span> is a number between 0 and 1, usually closer to zero (for example, 0.1) to “exploit” in most decisions. This way, the method allows continuous exploration of the alternative actions throughout the experiment.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="application-to-the-online-advertising-scenario">
<h1>Application to the online advertising scenario<a class="headerlink" href="#application-to-the-online-advertising-scenario" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">class</span> <span class="nc">BernoulliBandit</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
    
    <span class="k">def</span> <span class="nf">display_ad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reward</span>
    
<span class="n">bandit_probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.016</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.028</span><span class="p">,</span> <span class="mf">0.031</span><span class="p">]</span> <span class="c1">#These probabilities represent the reward distribution per each bandit (ad here).</span>

<span class="n">ads</span> <span class="o">=</span> <span class="p">[</span><span class="n">BernoulliBandit</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bandit_probs</span><span class="p">]</span>

<span class="n">n_trails</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">n_ads</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ads</span><span class="p">)</span>
<span class="n">epsilons</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">]</span>


<span class="k">for</span> <span class="n">epsilon</span> <span class="ow">in</span> <span class="n">epsilons</span><span class="p">:</span>
    <span class="n">n_optimal_pulls</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_explored</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_exploited</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_ads</span><span class="p">)</span>  <span class="c1"># Q, action values</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_ads</span><span class="p">)</span>  <span class="c1"># N, total impressions</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">avg_rewards</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Save average rewards over time</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trails</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="n">n_explored</span><span class="o">+=</span><span class="mi">1</span>
            <span class="n">ad_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_ads</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ad_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
            <span class="n">n_exploited</span><span class="o">+=</span><span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">ad_chosen</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">bandit_probs</span><span class="p">):</span>
                <span class="n">n_optimal_pulls</span> <span class="o">+=</span><span class="mi">1</span>

        <span class="n">R</span> <span class="o">=</span> <span class="n">ads</span><span class="p">[</span><span class="n">ad_chosen</span><span class="p">]</span><span class="o">.</span><span class="n">display_ad</span><span class="p">()</span>  <span class="c1"># Observe reward</span>
        <span class="n">N</span><span class="p">[</span><span class="n">ad_chosen</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">ad_chosen</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">N</span><span class="p">[</span><span class="n">ad_chosen</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">R</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">ad_chosen</span><span class="p">])</span>
        <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">R</span>
        <span class="n">avg_reward_so_far</span> <span class="o">=</span> <span class="n">total_reward</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">avg_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_reward_so_far</span><span class="p">)</span>

    <span class="n">best_ad_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>  <span class="c1"># Find the best action</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The best performing ad with epsilon </span><span class="si">{}</span><span class="s2"> is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="nb">chr</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">best_ad_index</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No. of times optimal ad was shown is&quot;</span><span class="p">,</span> <span class="n">n_optimal_pulls</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No. of times explored:&quot;</span><span class="p">,</span> <span class="n">n_explored</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No. of times exploited:&quot;</span><span class="p">,</span> <span class="n">n_exploited</span><span class="p">)</span>
    
    <span class="n">df_reward_comparison</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">avg_rewards</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A/B/n&#39;</span><span class="p">])</span>
    <span class="n">df_reward_comparison</span><span class="p">[</span><span class="s1">&#39;A/B/n&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;A/B/n Test Avg. Reward: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span>
                                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_reward_so_far</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Epsilon: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epsilon</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Impressions&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Avg. Reward&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The best performing ad with epsilon 0.1 is A
No. of times optimal ad was shown is 8378
No. of times explored: 1019
No. of times exploited: 8981
The best performing ad with epsilon 0.01 is A
No. of times optimal ad was shown is 9451
No. of times explored: 94
No. of times exploited: 9906
The best performing ad with epsilon 0.03 is A
No. of times optimal ad was shown is 9725
No. of times explored: 316
No. of times exploited: 9684
</pre></div>
</div>
<img alt="../_images/epsilon-greedy_2_1.png" src="../_images/epsilon-greedy_2_1.png" />
</div>
</div>
<p>From the above graph it is very clear that, with higher epsilon value, the agent explores more. While all the agents with different epsilon values converge to the similar final average reward and decide on the same best performing ad, the difference in the time taken for convergence is significant.</p>
<p>The number of optimal pulls (once converged) is significantly more for lower epsilon values. On the other hand, the noise (fluctuations) in case of epsilon=0.1 are significantly more.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="advantages-and-disadvantages-of-epsilon-greedy-actions">
<h1>Advantages and disadvantages of <span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy actions<a class="headerlink" href="#advantages-and-disadvantages-of-epsilon-greedy-actions" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p><strong>ε-greedy actions and A/B/n tests are similarly inefficient and static in allocating the exploration budget</strong>. The ε-greedy approach, too, fails to write off actions that are clearly bad and continues to allocate the same exploration budget to each alternative. For example, halfway through the experiment, it is pretty clear that ad A is performing pretty poorly. It would have been more efficient to use the exploration budget to try to differentiate between the rest of the alternatives to identify the best. On a related note, if a particular action is under-explored/over-explored at any point, the exploration budget is not adjusted accordingly.</p></li>
</ul>
<p>One potential solution to this problem can be the use of decaying epsilon where epsilon is a function of time step.</p>
<div class="math notranslate nohighlight">
\[
\epsilon(t) \propto 1/t, \enspace \epsilon(t) = max(\epsilon_0-kt, \epsilon_{min}), \enspace \epsilon(t) = \epsilon_0 \alpha^t, \enspace \epsilon(t)=\frac{a}{log(bt+c)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(t\)</span> is the time step.</p>
<ul class="simple">
<li><p><strong>With ε-greedy actions, exploration is continuous, unlike in A/B/n testing</strong>. This means if the environment is not stationary, the ε-greedy approach has the potential to pick up the changes and modify its selection of the best alternative. In stationary environments, though, we can expect the A/B/n testing and the ε-greedy approach to perform similarly since they are very similar in nature, except when they do the exploration.</p></li>
<li><p><strong>The ε-greedy actions approach could be made more efficient by dynamically changing the ε value</strong>. For example, you could start with a high ε value to explore more at the beginning and gradually decrease it to exploit more later. This way, there is still continuous exploration, but not as much as at the beginning when there was no knowledge of the environment.</p></li>
<li><p><strong>The ε-greedy actions approach could be made more dynamic by increasing the importance of more recent observations</strong>. In the standard version, the values in the preceding are calculated as simple averages. Remember that, in dynamic environments, we could instead use the following formula:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[Q_{n+1}(a) = Q_n(a)+\alpha (R_n(a)-Q_n(a))\]</div>
<p>This would exponentially diminish the weights of the older observations and enable the approach to detect the changes in the environment more easily.</p>
<ul class="simple">
<li><p><strong>Modifying the ε-greedy actions approach introduces new hyperparameters, which need to be tuned</strong>. Both of the previous suggestions – gradually diminishing ε and using exponential smoothing for Q – come with additional hyperparameters, and it may not be obvious what values to set these to. Moreover, incorrect selection of these hyperparameters may lead to worse results than what the standard version would yield.</p></li>
</ul>
<p>Keep in mind that ε-greedy actions are still too static, and we can do better. Consecutive sections discuss methods that improve upon ε-greedy.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://www.packtpub.com/product/mastering-reinforcement-learning-with-python/9781838644147">https://www.packtpub.com/product/mastering-reinforcement-learning-with-python/9781838644147</a></p></li>
</ul>
<p><em>This entire page is a chapter referenced from the above link. EssentialAI does not claim ownership of the content in any way.</em></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "EssentialAI/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./rl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ab-testing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">A/B/n testing using online advertising scenario</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="optimistic-initial-values.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Optimistic initial values</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Naresh Kumar<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>